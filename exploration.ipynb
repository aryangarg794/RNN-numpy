{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a RNN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logits: np.ndarray) -> np.ndarray:\n",
    "    return np.exp(logits - np.max(logits))/np.sum(np.exp(logits - np.max(logits)), axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65900114, 0.24243297, 0.09856589])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test softmax\n",
    "logits = np.array([2.0, 1.0, 0.1])\n",
    "softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell:\n",
    "\n",
    "    def __init__(self, dim_hidden_units, dim_input, batch_size, dim_output, activation=np.tanh) -> None:\n",
    "        # input size is ((n_x), m) where n_x is input dimensions\n",
    "        self.Wa = np.random.randn(dim_hidden_units, dim_input+dim_hidden_units) # we assume the last shape is T_x\n",
    "        self.Wy = np.random.randn(dim_output, dim_hidden_units)\n",
    "        self.ba = np.zeros((dim_hidden_units, 1))\n",
    "        self.by = np.zeros((1, 1))\n",
    "        self.activation = activation\n",
    "\n",
    "    def __call__(self, x: np.ndarray) -> tuple[np.ndarray, np.ndarray]: \n",
    "        hidden_state = self.activation(self.Wa @ x + self.ba)\n",
    "        y_hat = softmax(self.Wy @ hidden_state + self.by)\n",
    "        return hidden_state, y_hat\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'RNNCell()'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 1: Hidden state =\n",
      "[[-0.32622662  0.00199797]\n",
      " [-0.752167   -0.91085786]\n",
      " [ 0.92956147  0.95214357]\n",
      " [-0.82340251 -0.6967403 ]\n",
      " [ 0.26984353  0.72060859]], \n",
      "Y_hat = \n",
      "[[0.58785492 0.60734337]\n",
      " [0.04530643 0.01968375]\n",
      " [0.36683865 0.37297289]] \n",
      "Time step 2: Hidden state =\n",
      "[[ 0.20285604  0.04999598]\n",
      " [-0.99912931 -0.99962968]\n",
      " [ 0.35454741  0.86044744]\n",
      " [-0.99502696 -0.99255363]\n",
      " [ 0.93684784  0.92218082]], \n",
      "Y_hat = \n",
      "[[0.08397552 0.35150295]\n",
      " [0.01581646 0.01613345]\n",
      " [0.90020801 0.63236359]] \n",
      "Time step 3: Hidden state =\n",
      "[[ 0.05282222 -0.3378512 ]\n",
      " [-0.99925038 -0.99956888]\n",
      " [ 0.52258449  0.58295158]\n",
      " [-0.97999171 -0.9883243 ]\n",
      " [ 0.87255972  0.57738154]], \n",
      "Y_hat = \n",
      "[[0.13478624 0.13023652]\n",
      " [0.01940477 0.03385962]\n",
      " [0.84580899 0.83590386]] \n"
     ]
    }
   ],
   "source": [
    "# test rnn forward\n",
    "batch_size = 2\n",
    "seq_length = 3\n",
    "input_size = 4\n",
    "hidden_size = 5\n",
    "output_size = 3\n",
    "cell = RNNCell(hidden_size, input_size, batch_size, output_size)\n",
    "\n",
    "input_sequence = np.random.rand(input_size, batch_size, seq_length)\n",
    "hidden_state = np.zeros((hidden_size, batch_size))\n",
    "\n",
    "for t in range(seq_length):\n",
    "    input_t = input_sequence[:, :, t] \n",
    "    inp = np.vstack((input_t, hidden_state))\n",
    "    hidden_state, y_hat = cell(inp)\n",
    "    print(f\"Time step {t + 1}: Hidden state =\\n{hidden_state}, \\nY_hat = \\n{y_hat} \")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
